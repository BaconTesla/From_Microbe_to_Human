{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2aae515-41ff-4d55-9db4-a827fe1adcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdb0a90-bafb-4717-9351-82ba8c8e87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数\n",
    "# 1. 对于uniref检索结果，需要去NaN以及对于多keggid的unirefid，进行拆分\n",
    "def process_uniref(df):\n",
    "    # 去NaN\n",
    "    df = df[~df['KEGG'].isna()]\n",
    "    new_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        uniref_id = row['From']\n",
    "        kegg_ids = row['KEGG'].split(';') # 通过 ; 拆分 KEGG IDs\n",
    "        for kegg_id in kegg_ids:\n",
    "            if kegg_id:\n",
    "                new_rows.append({\n",
    "                    'Uniref_ID': uniref_id,\n",
    "                    'KEGG_ID': kegg_id\n",
    "                })\n",
    "    # 将新的字典列表转换为df\n",
    "    df_uniref_to_kegg = pd.DataFrame(new_rows)\n",
    "    \n",
    "    return df_uniref_to_kegg\n",
    "\n",
    "# 2. 定义一个将提取得到的文本转换为df的函数\n",
    "def webtext_to_df(x,cols):\n",
    "    rows = x.split('\\n')\n",
    "    data = [row.split('\\t') for row in rows]\n",
    "    df = pd.DataFrame(data, columns=cols)\n",
    "    df.drop(df.index[-1],inplace=True)\n",
    "    return df\n",
    "\n",
    "# 3. 合并数据框\n",
    "def merge_df(uniref2kegg, org2ko, ko2hsa, hsa):\n",
    "    merge_df = pd.merge(ko2hsa, hsa[['hsa:gene','info']], on='hsa:gene', how='left')\n",
    "    merge_df['info'] = merge_df['info'].apply(lambda x: x.split(',')[0])\n",
    "    merge_df2 = pd.merge(org2ko, merge_df, on='ko', how='right')\n",
    "    merge_df3 = pd.merge(uniref2kegg, merge_df2, on='org:gene', how='right')\n",
    "\n",
    "    final_merge_df = merge_df3[['Uniref_ID','info']]\n",
    "    final_merge_df = final_merge_df[~merge_df4.duplicated()] # 去冗余\n",
    "    final_merge_df.rename(columns = {'info':'gene_symbol'}, inplace = True)\n",
    "    final_merge_df['gene_symbol'] = final_merge_df['gene_symbol'].apply(lambda x: x.split(';')[0] if ';' in x else x)\n",
    "\n",
    "    return final_merge_df\n",
    "\n",
    "# 4. 转换为scfoundation能够识别的df\n",
    "def transform_to_scfoundation(gene_family_to_symbol, gene_family):\n",
    "    # 合并两个数据框，基于 uniref_ID 列\n",
    "    merged_gene_symbol = pd.merge(gene_family_to_symbol, gene_family, on='Uniref_ID', how='left')\n",
    "    # 去掉第一列，uniref_ID\n",
    "    merged_gene_symbol.drop(merged_gene_symbol.columns[0], axis=1, inplace=True) \n",
    "    # 计算重复出现的gene表达均值\n",
    "    avg_gene_expression = merged_gene_symbol.groupby('gene_symbol').mean().reset_index()\n",
    "    # 以第一列作为索引\n",
    "    avg_gene_expression.set_index(avg_gene_expression.columns[0], inplace=True)\n",
    "    # 转置，转置后才满足scfoundation的输入\n",
    "    avg_gene_expression_T =avg_gene_expression.transpose()\n",
    "\n",
    "    return avg_gene_expression_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ea5ca7-fa40-4ff6-a206-1d281957935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取uniref检索结果文件\n",
    "tmp_uniref_to_kegg = pd.read_csv(\"./idmapping_100000.tsv\",sep=\"\\t\")\n",
    "\n",
    "uniref_to_kegg = process_uniref(tmp_uniref_to_kegg)\n",
    "\n",
    "# 存储 新获得的 uniref_KEGG的df\n",
    "uniref_to_kegg.to_csv(\"./results/uniref_to_kegg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3603a8dc-215d-433e-aa6e-b437c0763208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 keggid_list 按 100 行分块\n",
    "chunk_size = 100\n",
    "\n",
    "# 初始化存储所有请求结果的变量\n",
    "all_results = []\n",
    "\n",
    "# 循环每个分块进行请求\n",
    "for i in range(0, len(uniref_to_kegg['KEGG_ID']), chunk_size):\n",
    "    # 获取当前的 100 行数据\n",
    "    current_chunk = uniref_to_kegg['KEGG_ID'][i:i + chunk_size]\n",
    "    \n",
    "    # 将列表转换为以加号（+）连接的字符串，适合 URL 请求格式\n",
    "    chunk_str = '+'.join(current_chunk)\n",
    "    \n",
    "    # 构建请求 URL\n",
    "    url = f'https://rest.kegg.jp/link/ko/{chunk_str}'\n",
    "    \n",
    "    try:\n",
    "        # 发送 GET 请求\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # 将请求的文本结果添加到总结果中\n",
    "            all_results.append(response.text)\n",
    "        else:\n",
    "            print(f\"请求失败！ HTTP 状态码: {response.status_code}\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求发生错误: {e}\")\n",
    "    \n",
    "    # 每次请求后睡眠1秒\n",
    "    time.sleep(1)\n",
    "\n",
    "# 将所有结果汇总为一个字符串\n",
    "final_result = ''.join(all_results)\n",
    "\n",
    "# 字符转换为df 这里表示 org:gene -> ko\n",
    "org_to_ko = webtext_to_df(final_result,cols=['org:gene','ko'])\n",
    "\n",
    "# 存储 新获得的 org:gene 到 ko 的 df\n",
    "# 去冗余\n",
    "nr_org_to_ko = org_to_ko.drop(org_to_ko[org_to_ko.duplicated()].index)\n",
    "\n",
    "nr_org_to_ko.to_csv(\"./results/nr_org_to_ko.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3f565-041c-4f4c-bb89-9a8ab6237df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 keggid_list 按 100 行分块\n",
    "chunk_size = 100\n",
    "\n",
    "# 初始化存储所有请求结果的变量\n",
    "all_results = []\n",
    "\n",
    "# 循环每个分块进行请求\n",
    "for i in range(0, len(nr_org_to_ko['ko']), chunk_size):\n",
    "    # 获取当前的 100 行数据\n",
    "    current_chunk = nr_org_to_ko['ko'][i:i + chunk_size]\n",
    "    \n",
    "    # 将列表转换为以加号（+）连接的字符串，适合 URL 请求格式\n",
    "    chunk_str = '+'.join(current_chunk)\n",
    "    \n",
    "    # 构建请求 URL\n",
    "    url = f'https://rest.kegg.jp/link/hsa/{chunk_str}'\n",
    "    \n",
    "    try:\n",
    "        # 发送 GET 请求\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # print(f\"请求成功！ 第 {i//chunk_size + 1} 批次\")\n",
    "            # 将请求的文本结果添加到总结果中\n",
    "            all_results.append(response.text)\n",
    "        else:\n",
    "            print(f\"请求失败！ HTTP 状态码: {response.status_code}\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求发生错误: {e}\")\n",
    "    \n",
    "    # 每次请求后睡眠1秒\n",
    "    time.sleep(1)\n",
    "\n",
    "# 将所有结果汇总为一个字符串\n",
    "final_result = ''.join(all_results)\n",
    "\n",
    "ko_to_hsa = webtext_to_df(final_result, cols = ['ko','hsa:gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085dbe7b-289e-46f5-b18e-8533819b5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsa_df = pd.read_csv('./hsa.txt', sep='\\t', names=['hsa:gene','type','sequence','info'])\n",
    "# 合并df\n",
    "gene_familt_to_symbol = merge_df(uniref_to_kegg, nr_org_to_ko, ko_to_hsa, hsa_df)\n",
    "gene_family_to_symbol['Uniref_ID'] = gene_family_to_symbol['Uniref_ID'].apply(lambda x: 'UniRef90_' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b7b42-7e5b-4d1a-b27c-3dc334cd1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取基因家族文件\n",
    "gene_family = pd.read_csv('2021-03-31.TettAJ_2016.gene_families.txt', sep='\\t', index_col=0)[:100000]\n",
    "# 重置索引，使 Uniref_ID 变为一列\n",
    "gene_family.reset_index(inplace=True)\n",
    "gene_family.rename(columns={'index': 'Uniref_ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d7f5e-a1ab-4bbd-ad1f-5e7bce0a62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_data = transform_to_scfoundation(gene_family_to_symbol, gene_family)\n",
    "\n",
    "bulk_data.to_csv('results/bulk_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
